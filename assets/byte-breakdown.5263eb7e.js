import{d as l,a as c,w as i,_ as h,o as d,b as n,e,u as s,C as r,g as a,p as u,i as f,j as p,P as g,c as m}from"./App.vue_vue_type_script_setup_true_lang.48784448.js";const y=""+new URL("evolution_1.4a7c98c5.png",import.meta.url).href,b=""+new URL("evolution_2.35ad36a3.png",import.meta.url).href,_=""+new URL("how_deepfakes_work_1.675f5a7a.png",import.meta.url).href,v=""+new URL("how_deepfakes_work_2.565f98d8.png",import.meta.url).href,t=o=>(u("data-v-d6bd7a19"),o=o(),f(),o),w=a(" How Deepfakes Work "),k=t(()=>e("div",null,[a(" Deepfakes, in short, use generative AI to map the face of a person onto the head of another person. Let us dive into the details of how the AI really works."),e("br")],-1)),T=t(()=>e("div",null,[a(" As with all other artificial intelligence, deepfake models rely on training using a large amount of data. This data is a large dataset of images or videos of the target person, which can be obtained from various sources such as publicly available images and videos, social media platforms, or private collections. This data allows the AI to be trained far more accurately than using just a few images."),e("br")],-1)),A=["src"],I=a(" The central dogma of deepfakes lies in its face detection technology. First, we have to know where the faces actually are; Face detection algorithms are used to identify the presence and location of faces in images or video frames. Once the faces are detected, they need to be aligned and normalized to ensure that the positioning of features, the size of faces and their orientation stay roughly the same in all the data. Without this step, training becomes significantly harder. "),x=t(()=>e("br",null,null,-1)),N=t(()=>e("br",null,null,-1)),D=a(" The next step is identifying where all the features of the face are. This is done using other types of AI, most commonly convolutional neural networks (CNNs). These networks take in the raw image of the face as the input, learning to identify features of the face with relatively little supervision. Using labels of features of the face rather than the whole image greatly increases the efficiency of deepfake models. The same thing is done for the source image or video so that the features of the target person's face can be mapped easily to the source face. This allows us to retain the facial expressions of the source face while having the appearance of the target face."),F=t(()=>e("br",null,null,-1)),H=t(()=>e("div",null,[a(" Next comes the process of generation. Nowadays, GANs are used for this purpose. First, an autoencoder is used to simplify the source image, while being able to reconstruct the modified image from the simplified data output. GANs consist of two networks: a generator and a discriminator. The generator generates fake images, and the discriminator tries to distinguish between real and fake images. Through an adversarial training process, where the error of the GAN decreases by generating images that the discriminator sees as real while the error of the discriminator decreases if it successfully identifies the output of the generator as fake, the generator learns to create increasingly realistic deepfake images. After training is done, only the generator is used to create fake images."),e("br")],-1)),S=["src"],L=a(" Some post-processing may have to be done to make the deepfakes generated more convincing. The generated face has to be blended into the target video or image to ensure that it seamlessly integrates with the surrounding context. This involves adjusting the lighting, color, and texture of the generated face to match the target scene. More advanced techniques may also consider factors like facial movements and expressions to make the deepfake more convincing. "),P=a(" Evolution of Deepfake Technology "),q=t(()=>e("div",null,[a(" Deepfake technology has undergone remarkable evolution since its inception, pushing the boundaries of what is possible in the realm of digital manipulation. "),e("br"),e("br"),a(" Initially, in the 1990s, deepfakes emerged as a method to swap faces in photos and videos using computational resources and technical expertise. For example, deepfakes are used to superimpose celebrities' faces onto thebodies of adult film actors. Limited technology meant that the early deepfakes exhibited noticeable flaws and artifacts, making them easier to detect. "),e("br"),e("br"),a(" However, as the technology advanced, the potential applications and sophistication of deepfakes increased, resulting in higher quality and more realistic generated content. With the introduction of more powerful machine learning algorithms and access to vast datasets, deepfakes have become increasingly convincing, making it challenging to distinguish them from genuine footage. For example, deepfakes can now encompass voice synthesis, body movements, and even entire personas. "),e("br"),e("br"),e("br"),a(" In 2014, Generative Adversarial Networks (GANs) were introduced as a breakthrough in machine learning. GANs are a type of neural network framework that consists of two main components: a generator and a discriminator. "),e("br"),e("br"),a(" The generator's role in GANs is to create synthetic data, such as images or videos, that resemble real data. Initially, the generator produces random output, which is then fed into the discriminator. The discriminator's task is to distinguish between real data and the generated data from the generator. "),e("br"),e("br"),a(" During the training process, the discriminator provides feedback to the generator by evaluating the authenticity of the generated data. The generator uses this feedback to iteratively improve its output, aiming to generate data that is increasingly difficult for the discriminator to distinguish from real data. This adversarial training process between the generator and discriminator continues until the generator becomes proficient at generating highly realistic output. "),e("br"),e("br"),a(" In the context of deepfakes, GANs are utilized to create convincing and deceptive content by training the generator specifically to produce synthetic images or videos that closely mimic the appearance of a specific target individual. The generator learns from a dataset consisting of real images or videos of the target individual, allowing it to capture their unique facial features, expressions, and other visual characteristics. By leveraging the power of GANs, deepfakes can generate content that is difficult to distinguish from authentic footage, enabling the creation of highly realistic digital manipulations. ")],-1)),G=["src"],M=["src"],j=t(()=>e("tr",null,[e("td",null,"Early deepfake"),e("td",null,"Late deepfake")],-1)),O=a(" The uncanny similarity in the appearances between the latest deepfakes and the person they are mimicking raised concerns about the potential misuse of the technology for malicious purposes, such as spreading disinformation, blackmail, or impersonation. "),W=t(()=>e("br",null,null,-1)),C=t(()=>e("br",null,null,-1)),R=a(' To counter the negative implications of deepfake technology, researchers and tech companies have been actively working on developing robust detection methods. These involve using machine learning algorithms to analyze visual and audio cues, identifying inconsistencies and anomalies that would not appear in a "normal" recording. '),U=t(()=>e("br",null,null,-1)),z=t(()=>e("br",null,null,-1)),B=a(" As deepfake technology continues to progress, it is crucial to strike a balance between its creative potential and the need for responsible use. Ethical considerations, regulations, and public awareness will play vital roles in shaping the future evolution of deepfake technology, ensuring it is harnessed for positive applications while mitigating its potential risks. "),K=a(" Applications and Misuse of Deepfakes "),E=a(" Deepfake technology, powered by artificial intelligence, has revolutionised the way we interact with media content. As AI and deepfake technology evolve, people are finding more and more applications of deepfakes across various industries. "),V=t(()=>e("br",null,null,-1)),J=t(()=>e("br",null,null,-1)),Y=a(" Deepfakes have many uses. One of which is that it can be used in entertainment. One of the more famous examples is a film called Rogue One. In the movie, several characters' actors were deceased and to recreate the shots, they utilised deepfake technologies to present characters on screen. At that time, the technology was still very much in its infancy so the uncanny valley was quite deep for that movie. However, with the advance of technology, realism has greatly increased and this was part of the reason that caused the SAG-AFTRA strikes as actors were afraid they would be replaced by this technology. "),$=t(()=>e("br",null,null,-1)),Q=t(()=>e("br",null,null,-1)),X=a(' Another thing it can be utilised in is art and history. Multiple figures and their speeches have been brought to life thanks to this technology. For instance, John F. Kennedy"s speech on the day of the assassination was recreated with this technology. The speech Nixon planned on giving if the moon landing failed was also recreated with deep fakes. This allows us to gain a whole new perspective on different historical events more interactively. '),Z=t(()=>e("br",null,null,-1)),ee=t(()=>e("br",null,null,-1)),te=a(' You may have also seen the video of the Mona Lisa moving. That video was also created with a deepfake. Famous painter Salvador Dal was also "brought to life" with this technology to say some of his famous quotes. This technology adds a whole new dimension to appreciating art. '),ae=t(()=>e("br",null,null,-1)),ie=t(()=>e("br",null,null,-1)),oe=a(` Marketers are also looking to jump on the bandwagon. This technology allows employees to create personalised messages for customers and have celebrities' faces cast over them to create a personalised message. One such example is "Lay's Messi Messages" where "Messi" would invite the viewer to see his game and say their name in a few different languages. However, the ethical implications of this application are still a subject of debate. Nevertheless, it remains one of the many uses of deepfake technology. `),ne=t(()=>e("br",null,null,-1)),se=t(()=>e("br",null,null,-1)),re=a(" Surprisingly, deepfake technology has found applications in the medical field as well. To train medical robots, a large amount of data is needed. This data is hard to obtain due to privacy concerns but deepfakes can provide this. One such case is when it provides realistic brain scans for other AI to train on, so the AI can better recognize patterns in brain diseases and better diagnose them. "),le=t(()=>e("br",null,null,-1)),ce=t(()=>e("br",null,null,-1)),he=a(" In addition to the benefits of deepfakes, we must also be aware of the malicious activities that can result from this technology. Deepfake scams now appear on the news more than ever before. Fraudsters can modify publicly available video and footage to cheat people out of money. In Hong Kong alone, several such cases have already been reported. For example, a finance employee working for a multinational company fell victim to a sophisticated scam involving deepfake technology. In this elaborate scheme, the fraudsters used deepfake technology to create virtual replicas of the company's chief financial officer and other staff members. The unsuspecting worker was deceived into participating in a video conference call with these deepfake impersonations. "),de=t(()=>e("br",null,null,-1)),ue=t(()=>e("br",null,null,-1)),fe=a(" The worker initially became suspicious when he received a message that claimed to be from the company's Chief Financial Officer based in the UK. The message discussed the necessity of conducting a confidential transaction, resembling a typical phishing email. However, the worker's doubts were set aside after the video call because the individuals present in the call appeared and sounded identical to his recognized colleagues. In the end, the worker was tricked into paying HKD$200 million. Furthermore, between July and September of 2023, a total of eight stolen Hong Kong identity cards, which had previously been reported as lost by their owners, were exploited for fraudulent purposes. These stolen cards were employed to initiate 90 loan applications and 54 bank account registrations. Remarkably, during these transactions, cutting-edge AI deepfake technology was utilized on at least 20 occasions to deceive facial recognition systems. By skillfully mimicking the appearances of the individuals depicted on the stolen identity cards, the deepfake creations successfully tricked the facial recognition programs, allowing the fraudsters to proceed with their illicit activities undetected. Another concerning incident occurred in late January 2024, when the internet witnessed the rapid dissemination of pornographic images featuring the renowned American pop star, Taylor Swift. What made this case particularly alarming was the fact that these explicit images were not real photographs but rather AI-generated deepfakes, highlighting the detrimental impact that artificial intelligence technology can have. "),pe=t(()=>e("br",null,null,-1)),ge=t(()=>e("br",null,null,-1)),me=a(" The emergence of deepfake technology also presents a significant peril to the integrity of elections globally. In the US, a fake version of President Joe Biden's voice had been used in automatically generated robocalls to discourage Democrats from taking part in the primary election in the state of New Hampshire. The voice on the call sounded remarkably like the president, and the catchphrase was a familiar one. "),ye=t(()=>e("br",null,null,-1)),be=t(()=>e("br",null,null,-1)),_e=a(" A similar situation unfolded in Slovakia in October 2023, just days before the polls opened. A fabricated audio clip purportedly showing one candidate discussing vote manipulation and raising beer prices began to circulate online. Ultimately, the pro-Western party lost to a pro-Russian politician, leading to speculation that the deepfake had influenced the outcome. "),ve=t(()=>e("br",null,null,-1)),we=t(()=>e("br",null,null,-1)),ke=a(" A particular concern is the personalised targeting of voters using AI. A possible scenario where a malicious actor deploys AI technology to mimic a real person's voice and misinforms voters about their specific polling locations is possible. This could be replicated across multiple languages and affect numerous voters. AI-generated fakes could target local elections, particularly given the decline of local news outlets. Synthetic media becomes particularly difficult for voters to navigate in these cases, as local journalists may be scarce or unable to tackle misinformation effectively. "),Te=t(()=>e("br",null,null,-1)),Ae=t(()=>e("br",null,null,-1)),Ie=a(" While deepfake technology presents various opportunities and benefits in entertainment, art, marketing, and even the medical field, it also poses significant risks and challenges. The rise of deepfake scams, as well as the potential for election interference and targeted misinformation, highlight the need for robust regulation and awareness. "),xe=a(" How to Spot Deepfakes "),Ne=a(" To spot deepfake images or videos, here are some tips. First of all, when you are in doubt about the authenticity of an image or video, slow down and look for unusual or unnatural visual elements. Look for any signs or inconsistencies that may indicate manipulation such as a mismatched earrings or glass frames, unusual ear and tooth shapes and loss of contrast, or other discrepancies. Look for irregular or unnatural eye movements, such as blinking that seems too frequent or not occurring at appropriate times. In deepfake videos, facial expressions or lip-syncing may also appear unnatural or out of sync with the audio. If something seems off, it could be a sign of a deepfake. "),De=t(()=>e("br",null,null,-1)),Fe=t(()=>e("br",null,null,-1)),He=a(" In addition, deepfake videos often exhibit visual anomalies like blurring, pixelation, or mismatched edges around the subject's face or objects in the video. These irregularities can be a strong indicator of manipulation. "),Se=t(()=>e("br",null,null,-1)),Le=t(()=>e("br",null,null,-1)),Pe=a(" Deepfake videos may have inconsistent lighting and shadows on the manipulated face or body, which can be a clue that the video has been digitally altered. Pay attention to any blurriness or distortion, especially at the edges, as deepfake algorithms may struggle to achieve perfection. Deepfakes may have variations in image resolution and overall video quality. "),qe=t(()=>e("br",null,null,-1)),Ge=t(()=>e("br",null,null,-1)),Me=a(" Moreover, it's crucial to verify the source and context of the video. If you do not trust a claim, an image or a video, you can also use a standard internet search or a reverse image search to check for duplicates or similar images and see what other people say about it. You should also cross-reference the video with trusted sources or news outlets to ensure its authenticity. "),je=t(()=>e("br",null,null,-1)),Oe=t(()=>e("br",null,null,-1)),We=t(()=>e("br",null,null,-1)),Ce=a(' The uncanny effect also plays a role in distinguishing deepfakes from real videos. It refers to the feeling of unease or discomfort that arises when a human-like entity, such as a robot, computer-generated character, or even a manipulated video, appears almost but not quite convincingly human. It is often associated with the phenomenon of the "uncanny valley," which suggests that as the appearance or behavior of an artificial entity becomes more human-like, there is a corresponding increase in the negative emotional response from humans.The uncanny effect plays a role in deepfakes because even though the technology can produce highly realistic results, there are often subtle imperfections or inconsistencies that can trigger a sense of unease or suspicion in viewers. When viewers sense that something is not quite right with a deepfake video, it can diminish the effectiveness of the deception. Therefore, trust your instincts if something feels too perfect or not quite right. '),Re=t(()=>e("br",null,null,-1)),Ue=t(()=>e("br",null,null,-1)),ze=a(" According to the Testing H10 of the research done by Ilkka Kaate and others, a repeated measures ANOVA was performed to compare the effect of persona modality on uncanny valley. There was a significant effect of persona modality on the uncanny valley between at least two groups. More detailed examination shows that deepfake personas exhibit a higher uncanny valley effect than narrative personas(NPs) and classic personas(CPs), while NPs and CPs do not exhibit significant differences. Therefore, H10 is fully supported: Deepfake personas result in a higher sense of abnormality than (a) classic persona profiles and (b) narrative personas. "),Be=l({__name:"Publication",setup(o){return(Ee,Ve)=>(d(),c(h,null,{default:i(()=>[n(r,null,{header:i(()=>[w]),default:i(()=>[k,T,e("div",null,[e("img",{class:"c-publication-image",src:s(_),width:"250"},null,8,A),I,x,N,D,F]),H,e("div",null,[e("img",{class:"c-publication-image",src:s(v),width:"250"},null,8,S),L])]),_:1}),n(r,null,{header:i(()=>[P]),default:i(()=>[q,e("div",null,[e("table",null,[e("tr",null,[e("td",null,[e("img",{src:s(y),height:"300"},null,8,G)]),e("td",null,[e("img",{src:s(b),height:"300"},null,8,M)])]),j]),O,W,C,R,U,z,B])]),_:1}),n(r,null,{header:i(()=>[K]),default:i(()=>[E,V,J,Y,$,Q,X,Z,ee,te,ae,ie,oe,ne,se,re,le,ce,he,de,ue,fe,pe,ge,me,ye,be,_e,ve,we,ke,Te,Ae,Ie]),_:1}),n(r,null,{header:i(()=>[xe]),default:i(()=>[Ne,De,Fe,He,Se,Le,Pe,qe,Ge,Me,je,Oe,We,Ce,Re,Ue,ze]),_:1})]),_:1}))}});const Ke=p(Be,[["__scopeId","data-v-d6bd7a19"]]);g.content.cards=[];m(Ke).mount("#app");
